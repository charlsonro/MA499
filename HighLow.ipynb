{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from random import shuffle\n",
    "import scipy.misc\n",
    "import scipy\n",
    "import time\n",
    "import skimage.io\n",
    "from skimage.io import imread\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras import optimizers, metrics, regularizers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, SeparableConv2D, core\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, Cropping2D, concatenate, Input\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.activations import softmax\n",
    "import keras.losses\n",
    "import matplotlib\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_one = 1\n",
    "class_weight_two = 1\n",
    "batch_size = 5\n",
    "epochs_2_train = 10\n",
    "validPercent = 0.1\n",
    "image_folder = '/data/Ro_ImageData/Low SN ratio ceramic images/' #Source of images\n",
    "highSN_label = '/data/Ro_ImageData/32xOTSU/' #Otsu images\n",
    "lowSN_label = '/data/Ro_ImageData/32xOTSULow'\n",
    "highSN_folder = '/data/Ro_ImageData/High SN ratio ceramic images/'\n",
    "lowSN_folder = '/data/Ro_ImageData/Low SN ratio ceramic images/'\n",
    "prediction_folder = '/home/dspuser/MA499/Predictions2/' #Folder for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(sample, highSN_folder, lowSN_folder, highSN_label, lowSN_label):\n",
    "    if ('_C' in sample):\n",
    "    #If it's a low SN image\n",
    "        inputImgPath = os.path.join(lowSN_folder, sample)\n",
    "        maskImgPath = os.path.join(lowSN_label, sample)\n",
    "    else:\n",
    "    #If it's a high SN image\n",
    "        inputImgPath = os.path.join(highSN_folder, sample)\n",
    "        maskImgPath = os.path.join(highSN_label, sample)\n",
    "    img_int = np.array(imread(inputImgPath), dtype = 'float32')/255\n",
    "    lbl_int = np.array(imread(maskImgPath), dtype = 'float32')/2**16\n",
    "    lbl_int[:,:,1] = 1-lbl_int[:,:,0]\n",
    "    lbl_int = lbl_int[:,:,0:2]\n",
    "    return img_int,lbl_int\n",
    "\n",
    "def get_sample_test(sample,test_folder):\n",
    "    img_int = np.array(imread(test_folder + sample), dtype = 'float32')/255\n",
    "    return img_int\n",
    "\n",
    "def data_generator(file_name_list,batch_size): #randomly sampled instances from file name list with batch size\n",
    "    while True:\n",
    "        batch_filenames = np.random.choice(file_name_list,batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for i_filename in batch_filenames:\n",
    "            Ai_img, Ai_mask = get_sample(i_filename,highSN_folder,lowSN_folder,highSN_label,lowSN_label)\n",
    "            batch_input += [Ai_img]\n",
    "            batch_output += [Ai_mask]\n",
    "            #print(i_filename)\n",
    "        batch_img = np.expand_dims(np.array(batch_input,dtype='float32'),axis=-1)\n",
    "        batch_mask = np.array(batch_output,dtype='float32')\n",
    "        yield (batch_img,batch_mask)\n",
    "\n",
    "def Weighted_Binary_CrossEntropy(y_true_n,y_pred_n):\n",
    "    b_ce = K.binary_crossentropy(y_true_n,y_pred_n)\n",
    "    y_true = K.cast(K.expand_dims(K.argmax(y_true_n,axis=-1),axis=-1),dtype='float32')\n",
    "    y_pred = K.cast(K.expand_dims(K.argmax(y_pred_n,axis=-1),axis=-1),dtype='float32')\n",
    "    #Pixel Disparity\n",
    "    one_weight = class_weight_one\n",
    "    zero_weight = class_weight_two\n",
    "    weight_vector = y_true * one_weight + (1.-y_true)*zero_weight\n",
    "    weighted_b_ce = weight_vector*b_ce\n",
    "    return K.mean(weighted_b_ce)\n",
    "\n",
    "keras.losses.Weighted_Binary_CrossEntropy = Weighted_Binary_CrossEntropy\n",
    "\n",
    "def makeSampleList(highSN_folder,lowSN_folder,sampleSize,prop):\n",
    "    sampleList = []\n",
    "    highSN = os.listdir(highSN_folder)\n",
    "    #highSN = [os.path.join(highSN_folder,file) for file in highSN]\n",
    "    lowSN = os.listdir(lowSN_folder)\n",
    "    #lowSN = [os.path.join(lowSN_folder,file) for file in lowSN]\n",
    "    highSample = list(np.random.choice(highSN,sampleSize-round(sampleSize*prop)))\n",
    "    lowSample = list(np.random.choice(lowSN,round(sampleSize*prop)))\n",
    "    sampleListAll = highSample + lowSample\n",
    "    for file in sampleListAll:\n",
    "        if os.path.splitext(file)[1] == '.tiff':\n",
    "            sampleList.append(file)\n",
    "    return sampleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleList = makeSampleList(highSN_folder,lowSN_folder,2000,0.5)\n",
    "indexes_valid = random.sample(range(0,len(sampleList)),int(validPercent*float(len(sampleList))))\n",
    "indexes_train = [x for x in range(0,len(sampleList)) if x not in indexes_valid]\n",
    "training_list = [x for ind,x in enumerate(sampleList) if ind in indexes_train]\n",
    "valid_list = [x for ind,x in enumerate(sampleList) if ind in indexes_valid]\n",
    "num_train_calls = int(float(len(training_list)+1)/float(batch_size))\n",
    "num_valid_calls = int(float(len(valid_list)+1)/float(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_81 (Conv2D)           (None, 1024, 1024, 10)    100       \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 1024, 1024, 10)    40        \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 1024, 1024, 10)    910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 1024, 1024, 10)    40        \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 1024, 1024, 10)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 1024, 1024, 10)    910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 1024, 1024, 10)    40        \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 1024, 1024, 10)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 1024, 1024, 10)    910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 1024, 1024, 10)    40        \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 1024, 1024, 10)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 1024, 1024, 2)     22        \n",
      "=================================================================\n",
      "Total params: 3,012\n",
      "Trainable params: 2,932\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/skimage/external/tifffile/tifffile.py:2616: RuntimeWarning: py_decodelzw encountered unexpected end of stream\n",
      "  strip = decompress(strip)\n",
      "/opt/conda/lib/python3.7/site-packages/skimage/external/tifffile/tifffile.py:2551: UserWarning: unpack: buffer size must be a multiple of element size\n",
      "  warnings.warn(\"unpack: %s\" % e)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 48s 956ms/step - loss: 0.9702 - accuracy: 0.7055 - val_loss: 1.5602 - val_accuracy: 0.3757\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 45s 908ms/step - loss: 0.8779 - accuracy: 0.7668 - val_loss: 1.2394 - val_accuracy: 0.3097\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 40s 801ms/step - loss: 0.8366 - accuracy: 0.7944 - val_loss: 1.0441 - val_accuracy: 0.5936\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 45s 902ms/step - loss: 0.8058 - accuracy: 0.8093 - val_loss: 1.0104 - val_accuracy: 0.6412\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 45s 897ms/step - loss: 0.7739 - accuracy: 0.8296 - val_loss: 0.8680 - val_accuracy: 0.7903\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 45s 899ms/step - loss: 0.7612 - accuracy: 0.8351 - val_loss: 0.7051 - val_accuracy: 0.8327\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 45s 905ms/step - loss: 0.7288 - accuracy: 0.8556 - val_loss: 0.6383 - val_accuracy: 0.8949\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 46s 914ms/step - loss: 0.7141 - accuracy: 0.8632 - val_loss: 0.6348 - val_accuracy: 0.9149\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 45s 906ms/step - loss: 0.7088 - accuracy: 0.8681 - val_loss: 0.5946 - val_accuracy: 0.9207\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 45s 908ms/step - loss: 0.7012 - accuracy: 0.8694 - val_loss: 0.6595 - val_accuracy: 0.9121\n"
     ]
    }
   ],
   "source": [
    "#### Network is built ####\n",
    "network = Sequential()\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),input_shape = (1024,1024,1),\n",
    "padding = 'same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Dropout(0.25))\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Dropout(0.25))\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Dropout(0.25))\n",
    "network.add(Conv2D(2,(1,1),activation = 'softmax',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "sgd = optimizers.SGD(lr = 0.0001, decay = 1e-8, momentum = 0.9, nesterov = False)\n",
    "network.compile(loss = Weighted_Binary_CrossEntropy, optimizer = sgd, metrics = ['accuracy'])\n",
    "network.summary()\n",
    "network_training = network.fit_generator(data_generator(training_list,batch_size),steps_per_epoch = 50, \n",
    "                                         epochs = epochs_2_train, verbose = 1,validation_data = data_generator(valid_list,batch_size),\n",
    "                                         validation_steps = num_valid_calls)\n",
    "TP = 0 #True Positives\n",
    "TN = 0 #True Negatives\n",
    "FP = 0 #False Positives\n",
    "FN = 0 #False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in valid_list: #Use for new lists\n",
    "    img,lbl = get_sample(filename,highSN_folder,lowSN_folder,highSN_label,lowSN_label)\n",
    "    lbl = np.argmax(lbl,axis=-1)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    img = np.expand_dims(img,axis=-1)\n",
    "    img_pred = network.predict(img)\n",
    "    pred = np.argmax(img_pred[0,:,:,:],axis=-1)\n",
    "    TP += np.sum(pred*lbl,dtype='float32')\n",
    "    TN += np.sum((1-pred)*(1-lbl),dtype='float32')\n",
    "    FP += np.sum((1-pred)*lbl,dtype='float32')\n",
    "    FN += np.sum(pred*(1-lbl),dtype='float32')\n",
    "\n",
    "ACC = (TP + TN)/(TP + TN + FP + FN) #Accuracy\n",
    "Recall = (TP)/(TP + FN)\n",
    "Precision = (TP)/(TP + FP)\n",
    "MCC = ((TP * TN) - (FP * FN))/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "\n",
    "np.savetxt('ValidationMetrics2.txt',(ACC,Recall,Precision,MCC))\n",
    "np.savetxt('ValidationLoss2.txt',network_training.history['val_loss'])\n",
    "np.savetxt('ValidationAcc2.txt',network_training.history['val_accuracy'])\n",
    "test_list = valid_list\n",
    "network.save(\"H50_L50.h5\") \n",
    "model = keras.models.load_model(\"H50_L50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/dspuser/MA499/Predictions2/Tile_r015_c001.tiff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c8e0dab262b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mbackground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/dspuser/MA499/Predictions2/Tile_r015_c001.tiff'"
     ]
    }
   ],
   "source": [
    "### Generate predictions from trained model ###\n",
    "for filename in test_list:\n",
    "    img,lbl = get_sample(filename, highSN_folder, lowSN_folder, highSN_label, lowSN_label)\n",
    "    lbl = np.argmax(lbl,axis=-1)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    img = np.expand_dims(img,axis=-1)\n",
    "    img_pred = model.predict(img)\n",
    "    pred = np.argmax(img_pred[0,:,:,:],axis=-1)\n",
    "    matplotlib.image.imsave(prediction_folder+filename,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
