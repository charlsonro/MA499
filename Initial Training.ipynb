{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 1024, 1024, 10)    100       \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 1024, 1024, 10)    40        \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 1024, 1024, 10)    910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 1024, 1024, 10)    40        \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1024, 1024, 10)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 1024, 1024, 10)    910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 1024, 1024, 10)    40        \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 1024, 1024, 10)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 1024, 1024, 10)    910       \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 1024, 1024, 10)    40        \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 1024, 1024, 10)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 1024, 1024, 2)     22        \n",
      "=================================================================\n",
      "Total params: 3,012\n",
      "Trainable params: 2,932\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 1.3996 - accuracy: 0.5077 - val_loss: 8.6857 - val_accuracy: 0.3402\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 27s 534ms/step - loss: 1.3473 - accuracy: 0.5107 - val_loss: 5.5567 - val_accuracy: 0.3321\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 1.3053 - accuracy: 0.5127 - val_loss: 3.5398 - val_accuracy: 0.3408\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 27s 535ms/step - loss: 1.2662 - accuracy: 0.5187 - val_loss: 2.8125 - val_accuracy: 0.4082\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 26s 522ms/step - loss: 1.2338 - accuracy: 0.5249 - val_loss: 1.6747 - val_accuracy: 0.4316\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 1.1941 - accuracy: 0.5346 - val_loss: 1.3761 - val_accuracy: 0.4438\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 26s 519ms/step - loss: 1.1644 - accuracy: 0.5351 - val_loss: 1.3448 - val_accuracy: 0.4625\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 1.1386 - accuracy: 0.5492 - val_loss: 1.1567 - val_accuracy: 0.4773\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 1.1335 - accuracy: 0.5452 - val_loss: 1.1259 - val_accuracy: 0.4977\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 1.1254 - accuracy: 0.5441 - val_loss: 1.0464 - val_accuracy: 0.5203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n### Generate predictions from trained model ###\\nfor filename in test_list:\\n    img,lbl = get_sample(filename,image_folder,label_folder)\\n    lbl = np.argmax(lbl,axis=-1)\\n    img = np.expand_dims(img,axis=0)\\n    img = np.expand_dims(img,axis=-1)\\n    img_pred = network.predict(img)\\n    pred = np.argmax(img_pred[0,:,:,:],axis=-1)\\n    matplotlib.image.imsave(prediction_folder+filename,pred)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from random import shuffle\n",
    "import scipy.misc\n",
    "import scipy\n",
    "import time\n",
    "import skimage.io\n",
    "from skimage.io import imread\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras import optimizers, metrics, regularizers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, SeparableConv2D, core\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, Cropping2D, concatenate, Input\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.activations import softmax\n",
    "import matplotlib\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_weight_one = 1\n",
    "class_weight_two = 1\n",
    "batch_size = 2\n",
    "epochs_2_train = 10\n",
    "validPercent = 0.1\n",
    "image_folder = '/data/Ro_ImageData/Low SN ratio ceramic images/' #Source of images\n",
    "label_folder = '/data/Ro_ImageData/32xOTSU/' #Otsu images\n",
    "prediction_folder = '/home/dspuser/MA499/Predictions/' #Folder for predictions\n",
    "\n",
    "def get_sample(sample,image_folder,label_folder):\n",
    "    inputImg = sample\n",
    "    maskImg = sample.split('_C')[0] + '.tiff'\n",
    "    img_int = np.array(imread(image_folder + inputImg), dtype = 'float32')/255\n",
    "    lbl_int = np.array(imread(label_folder + maskImg), dtype = 'float32')/2**16\n",
    "    lbl_int[:,:,1] = 1-lbl_int[:,:,0]\n",
    "    lbl_int = lbl_int[:,:,0:2]\n",
    "    return img_int,lbl_int\n",
    "\n",
    "def get_sample_test(sample,test_folder):\n",
    "    img_int = np.array(imread(test_folder + sample), dtype = 'float32')/255\n",
    "    return img_int\n",
    "\n",
    "def data_generator(file_name_list,batch_size): #randomly sampled instances from file name list with batch size\n",
    "    while True:\n",
    "        batch_filenames = np.random.choice(file_name_list,batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for i_filename in batch_filenames:\n",
    "            Ai_img, Ai_mask = get_sample(i_filename,image_folder,label_folder)\n",
    "            batch_input += [Ai_img]\n",
    "            batch_output += [Ai_mask]\n",
    "            #print(i_filename)\n",
    "        batch_img = np.expand_dims(np.array(batch_input,dtype='float32'),axis=-1)\n",
    "        batch_mask = np.array(batch_output,dtype='float32')\n",
    "        yield (batch_img,batch_mask)\n",
    "\n",
    "def Weighted_Binary_CrossEntropy(y_true_n,y_pred_n):\n",
    "    b_ce = K.binary_crossentropy(y_true_n,y_pred_n)\n",
    "    y_true = K.cast(K.expand_dims(K.argmax(y_true_n,axis=-1),axis=-1),dtype='float32')\n",
    "    y_pred = K.cast(K.expand_dims(K.argmax(y_pred_n,axis=-1),axis=-1),dtype='float32')\n",
    "    #Pixel Disparity\n",
    "    one_weight = class_weight_one\n",
    "    zero_weight = class_weight_two\n",
    "    weight_vector = y_true * one_weight + (1.-y_true)*zero_weight\n",
    "    weighted_b_ce = weight_vector*b_ce\n",
    "    return K.mean(weighted_b_ce)\n",
    "\n",
    "\n",
    "sampleListAll = os.listdir(image_folder)\n",
    "\n",
    "for file in sampleListAll:\n",
    "    if os.path.splitext(file)[1] == '.tiff':\n",
    "        sampleList.append(file)\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "indexes_valid = random.sample(range(0,len(sampleList)),int(validPercent*float(len(sampleList))))\n",
    "indexes_train = [x for x in range(0,len(sampleList)) if x not in indexes_valid]\n",
    "training_list = [x for ind,x in enumerate(sampleList) if ind in indexes_train]\n",
    "valid_list = [x for ind,x in enumerate(sampleList) if ind in indexes_valid]\n",
    "#(batch1,batch2) = data_generator(training_list,batch_size)\n",
    "#print(batch1.shape)\n",
    "#print(batch2.shape)\n",
    "\n",
    "'''\n",
    "\n",
    "test1,test2 = get_sample(training_list[0])\n",
    "print(np.max(test2))\n",
    "print(np.min(test2))\n",
    "matplotlib.image.imsave('test1.png',test1)\n",
    "matplotlib.image.imsave('test2.png',test2)\n",
    "\n",
    "'''\n",
    "num_train_calls = int(float(len(training_list)+1)/float(batch_size))\n",
    "num_valid_calls = int(float(len(valid_list)+1)/float(batch_size))\n",
    "\n",
    "#### Network is built ####\n",
    "network = Sequential()\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),input_shape = (1024,1024,1),\n",
    "padding = 'same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Dropout(0.25))\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Dropout(0.25))\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Dropout(0.25))\n",
    "network.add(Conv2D(2,(1,1),activation = 'softmax',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "sgd = optimizers.SGD(lr = 0.0001, decay = 1e-8, momentum = 0.9, nesterov = False)\n",
    "network.compile(loss = Weighted_Binary_CrossEntropy, optimizer = sgd, metrics = ['accuracy'])\n",
    "network.summary()\n",
    "#network.load_weights('weights.h5')\n",
    "network_training = network.fit_generator(data_generator(training_list,batch_size),\n",
    "steps_per_epoch = 50, epochs = epochs_2_train, verbose = 1,validation_data = \n",
    "data_generator(valid_list,batch_size),validation_steps = num_valid_calls)\n",
    "#network.save_weights('weights.h5')\n",
    "TP = 0 #True Positives\n",
    "TN = 0 #True Negatives\n",
    "FP = 0 #False Positives\n",
    "FN = 0 #False Negatives\n",
    "\n",
    "for filename in valid_list: #Use for new lists\n",
    "    img,lbl = get_sample(filename,image_folder,label_folder)\n",
    "    lbl = np.argmax(lbl,axis=-1)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    img = np.expand_dims(img,axis=-1)\n",
    "    img_pred = network.predict(img)\n",
    "    pred = np.argmax(img_pred[0,:,:,:],axis=-1)\n",
    "    TP += np.sum(pred*lbl,dtype='float32')\n",
    "    TN += np.sum((1-pred)*(1-lbl),dtype='float32')\n",
    "    FP += np.sum((1-pred)*lbl,dtype='float32')\n",
    "    FN += np.sum(pred*(1-lbl),dtype='float32')\n",
    "\n",
    "ACC = (TP + TN)/(TP + TN + FP + FN) #Accuracy\n",
    "Recall = (TP)/(TP + FN)\n",
    "Precision = (TP)/(TP + FP)\n",
    "MCC = ((TP * TN) - (FP * FN))/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "\n",
    "np.savetxt('ValidationMetrics2.txt',(ACC,Recall,Precision,MCC))\n",
    "np.savetxt('ValidationLoss2.txt',network_training.history['val_loss'])\n",
    "np.savetxt('ValidationAcc2.txt',network_training.history['val_accuracy'])\n",
    "\n",
    "'''\n",
    "plt.plot([1,2])\n",
    "plt.ylabel(network_training.history['val_acc'])\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "test_list = valid_list\n",
    "'''\n",
    "### Generate predictions from trained model ###\n",
    "for filename in test_list:\n",
    "    img,lbl = get_sample(filename,image_folder,label_folder)\n",
    "    lbl = np.argmax(lbl,axis=-1)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    img = np.expand_dims(img,axis=-1)\n",
    "    img_pred = network.predict(img)\n",
    "    pred = np.argmax(img_pred[0,:,:,:],axis=-1)\n",
    "    matplotlib.image.imsave(prediction_folder+filename,pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_folder = '/home/dspuser/MA499/Predictions/' #Folder for predictions\n",
    "test_list = valid_list\n",
    "for filename in test_list:\n",
    "    img,lbl = get_sample(filename,image_folder,label_folder)\n",
    "    lbl = np.argmax(lbl,axis=-1)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    img = np.expand_dims(img,axis=-1)\n",
    "    img_pred = network.predict(img)\n",
    "    pred = np.argmax(img_pred[0,:,:,:],axis=-1)\n",
    "    matplotlib.image.imsave(prediction_folder+filename,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[4.08953913e-02, 9.59104598e-01],\n",
       "         [2.86899805e-01, 7.13100255e-01],\n",
       "         [2.55960273e-04, 9.99743998e-01],\n",
       "         ...,\n",
       "         [5.55715133e-07, 9.99999404e-01],\n",
       "         [2.59438650e-07, 9.99999762e-01],\n",
       "         [1.01332866e-01, 8.98667097e-01]],\n",
       "\n",
       "        [[1.43952379e-02, 9.85604703e-01],\n",
       "         [1.61494652e-04, 9.99838471e-01],\n",
       "         [3.84293380e-04, 9.99615669e-01],\n",
       "         ...,\n",
       "         [4.71111089e-02, 9.52888906e-01],\n",
       "         [1.61086628e-08, 1.00000000e+00],\n",
       "         [4.65085894e-01, 5.34914076e-01]],\n",
       "\n",
       "        [[9.20047518e-04, 9.99079943e-01],\n",
       "         [9.09818470e-01, 9.01815668e-02],\n",
       "         [1.36495659e-08, 1.00000000e+00],\n",
       "         ...,\n",
       "         [2.37011317e-08, 1.00000000e+00],\n",
       "         [8.35604386e-09, 1.00000000e+00],\n",
       "         [4.16931385e-07, 9.99999642e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[8.59623123e-03, 9.91403759e-01],\n",
       "         [7.50332233e-03, 9.92496729e-01],\n",
       "         [4.41316705e-11, 1.00000000e+00],\n",
       "         ...,\n",
       "         [8.85718942e-01, 1.14281073e-01],\n",
       "         [3.61273110e-01, 6.38726890e-01],\n",
       "         [2.51686007e-01, 7.48313963e-01]],\n",
       "\n",
       "        [[1.11171914e-11, 1.00000000e+00],\n",
       "         [4.63819169e-02, 9.53618050e-01],\n",
       "         [2.55912650e-24, 1.00000000e+00],\n",
       "         ...,\n",
       "         [2.14681113e-05, 9.99978542e-01],\n",
       "         [4.91014635e-03, 9.95089769e-01],\n",
       "         [8.90728272e-03, 9.91092741e-01]],\n",
       "\n",
       "        [[3.02690609e-07, 9.99999642e-01],\n",
       "         [1.56294334e-16, 1.00000000e+00],\n",
       "         [8.70737094e-10, 1.00000000e+00],\n",
       "         ...,\n",
       "         [1.81320909e-04, 9.99818742e-01],\n",
       "         [1.22006582e-02, 9.87799287e-01],\n",
       "         [9.09577124e-03, 9.90904272e-01]]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
