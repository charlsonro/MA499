{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('<U68'), dtype('<U68')) -> dtype('<U68')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8a4aa0743c30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msampleList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0msampleList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeSampleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhighSN_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlowSN_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mindexes_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidPercent\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8a4aa0743c30>\u001b[0m in \u001b[0;36mmakeSampleList\u001b[0;34m(highSN_folder, lowSN_folder, sampleSize, prop)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mhighSample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhighSN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msampleSize\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleSize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mlowSample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowSN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleSize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0msampleList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhighSample\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlowSample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampleList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.tiff'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U68'), dtype('<U68')) -> dtype('<U68')"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from random import shuffle\n",
    "import scipy.misc\n",
    "import scipy\n",
    "import time\n",
    "import skimage.io\n",
    "from skimage.io import imread\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras import optimizers, metrics, regularizers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, SeparableConv2D, core\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, Cropping2D, concatenate, Input\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.activations import softmax\n",
    "import matplotlib\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_weight_one = 1\n",
    "class_weight_two = 1\n",
    "batch_size = 2\n",
    "epochs_2_train = 10\n",
    "validPercent = 0.1\n",
    "image_folder = '/data/Ro_ImageData/Low SN ratio ceramic images/' #Source of images\n",
    "label_folder = '/data/Ro_ImageData/32xOTSU/' #Otsu images\n",
    "highSN_folder = '/data/Ro_ImageData/High SN ratio ceramic images/'\n",
    "lowSN_folder = '/data/Ro_ImageData/Low SN ratio ceramic images/'\n",
    "prediction_folder = '/home/dspuser/MA499/Predictions/' #Folder for predictions\n",
    "\n",
    "def get_sample(sample,image_folder,label_folder):\n",
    "    inputImg = sample\n",
    "    maskImg = sample.split('_C')[0] + '.tiff'\n",
    "    img_int = np.array(imread(image_folder + inputImg), dtype = 'float32')/255\n",
    "    lbl_int = np.array(imread(label_folder + maskImg), dtype = 'float32')/2**16\n",
    "    lbl_int[:,:,1] = 1-lbl_int[:,:,0]\n",
    "    lbl_int = lbl_int[:,:,0:2]\n",
    "    return img_int,lbl_int\n",
    "\n",
    "def get_sample_test(sample,test_folder):\n",
    "    img_int = np.array(imread(test_folder + sample), dtype = 'float32')/255\n",
    "    return img_int\n",
    "\n",
    "def data_generator(file_name_list,batch_size): #randomly sampled instances from file name list with batch size\n",
    "    while True:\n",
    "        batch_filenames = np.random.choice(file_name_list,batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for i_filename in batch_filenames:\n",
    "            Ai_img, Ai_mask = get_sample(i_filename,image_folder,label_folder)\n",
    "            batch_input += [Ai_img]\n",
    "            batch_output += [Ai_mask]\n",
    "            #print(i_filename)\n",
    "        batch_img = np.expand_dims(np.array(batch_input,dtype='float32'),axis=-1)\n",
    "        batch_mask = np.array(batch_output,dtype='float32')\n",
    "        yield (batch_img,batch_mask)\n",
    "\n",
    "def Weighted_Binary_CrossEntropy(y_true_n,y_pred_n):\n",
    "    b_ce = K.binary_crossentropy(y_true_n,y_pred_n)\n",
    "    y_true = K.cast(K.expand_dims(K.argmax(y_true_n,axis=-1),axis=-1),dtype='float32')\n",
    "    y_pred = K.cast(K.expand_dims(K.argmax(y_pred_n,axis=-1),axis=-1),dtype='float32')\n",
    "    #Pixel Disparity\n",
    "    one_weight = class_weight_one\n",
    "    zero_weight = class_weight_two\n",
    "    weight_vector = y_true * one_weight + (1.-y_true)*zero_weight\n",
    "    weighted_b_ce = weight_vector*b_ce\n",
    "    return K.mean(weighted_b_ce)\n",
    "\n",
    "'''\n",
    "sampleListAll = os.listdir(image_folder)\n",
    "\n",
    "for file in sampleListAll:\n",
    "    if os.path.splitext(file)[1] == '.tiff':\n",
    "        sampleList.append(file)\n",
    "'''\n",
    "\n",
    "def makeSampleList(highSN_folder,lowSN_folder,sampleSize,prop):\n",
    "    highSN = os.listdir(highSN_folder)\n",
    "    highSN = [os.path.join(highSN_folder,file) for file in highSN]\n",
    "    lowSN = os.listdir(lowSN_folder)\n",
    "    lowSN = [os.path.join(lowSN_folder,file) for file in lowSN]\n",
    "    highSample = np.random.choice(highSN,sampleSize-int(sampleSize*prop))\n",
    "    lowSample = np.random.choice(lowSN,int(sampleSize*prop))\n",
    "    sampleList = highSample + lowSample\n",
    "    for file in sampleList:\n",
    "        if os.path.splitext(file)[1] == '.tiff':\n",
    "            sampleList.append(file)\n",
    "    return sampleList\n",
    "\n",
    "sampleList = makeSampleList(highSN_folder,lowSN_folder,2000,0.025)\n",
    "\n",
    "indexes_valid = random.sample(range(0,len(sampleList)),int(validPercent*float(len(sampleList))))\n",
    "indexes_train = [x for x in range(0,len(sampleList)) if x not in indexes_valid]\n",
    "training_list = [x for ind,x in enumerate(sampleList) if ind in indexes_train]\n",
    "valid_list = [x for ind,x in enumerate(sampleList) if ind in indexes_valid]\n",
    "#(batch1,batch2) = data_generator(training_list,batch_size)\n",
    "#print(batch1.shape)\n",
    "#print(batch2.shape)\n",
    "\n",
    "'''\n",
    "\n",
    "test1,test2 = get_sample(training_list[0])\n",
    "print(np.max(test2))\n",
    "print(np.min(test2))\n",
    "matplotlib.image.imsave('test1.png',test1)\n",
    "matplotlib.image.imsave('test2.png',test2)\n",
    "\n",
    "'''\n",
    "num_train_calls = int(float(len(training_list)+1)/float(batch_size))\n",
    "num_valid_calls = int(float(len(valid_list)+1)/float(batch_size))\n",
    "\n",
    "#### Network is built ####\n",
    "network = Sequential()\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),input_shape = (1024,1024,1),\n",
    "padding = 'same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Dropout(0.25))\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Dropout(0.25))\n",
    "network.add(Conv2D(10,(3,3),activation = 'relu',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "network.add(keras.layers.BatchNormalization())\n",
    "network.add(Dropout(0.25))\n",
    "network.add(Conv2D(2,(1,1),activation = 'softmax',kernel_regularizer = regularizers.l2(.01),padding='same'))\n",
    "sgd = optimizers.SGD(lr = 0.0001, decay = 1e-8, momentum = 0.9, nesterov = False)\n",
    "network.compile(loss = Weighted_Binary_CrossEntropy, optimizer = sgd, metrics = ['accuracy'])\n",
    "network.summary()\n",
    "#network.load_weights('weights.h5')\n",
    "network_training = network.fit_generator(data_generator(training_list,batch_size),\n",
    "steps_per_epoch = 50, epochs = epochs_2_train, verbose = 1,validation_data = \n",
    "data_generator(valid_list,batch_size),validation_steps = num_valid_calls)\n",
    "#network.save_weights('weights.h5')\n",
    "TP = 0 #True Positives\n",
    "TN = 0 #True Negatives\n",
    "FP = 0 #False Positives\n",
    "FN = 0 #False Negatives\n",
    "\n",
    "for filename in valid_list: #Use for new lists\n",
    "    img,lbl = get_sample(filename,image_folder,label_folder)\n",
    "    lbl = np.argmax(lbl,axis=-1)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    img = np.expand_dims(img,axis=-1)\n",
    "    img_pred = network.predict(img)\n",
    "    pred = np.argmax(img_pred[0,:,:,:],axis=-1)\n",
    "    TP += np.sum(pred*lbl,dtype='float32')\n",
    "    TN += np.sum((1-pred)*(1-lbl),dtype='float32')\n",
    "    FP += np.sum((1-pred)*lbl,dtype='float32')\n",
    "    FN += np.sum(pred*(1-lbl),dtype='float32')\n",
    "\n",
    "ACC = (TP + TN)/(TP + TN + FP + FN) #Accuracy\n",
    "Recall = (TP)/(TP + FN)\n",
    "Precision = (TP)/(TP + FP)\n",
    "MCC = ((TP * TN) - (FP * FN))/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "\n",
    "np.savetxt('ValidationMetrics2.txt',(ACC,Recall,Precision,MCC))\n",
    "np.savetxt('ValidationLoss2.txt',network_training.history['val_loss'])\n",
    "np.savetxt('ValidationAcc2.txt',network_training.history['val_accuracy'])\n",
    "\n",
    "'''\n",
    "plt.plot([1,2])\n",
    "plt.ylabel(network_training.history['val_acc'])\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "test_list = valid_list\n",
    "'''\n",
    "### Generate predictions from trained model ###\n",
    "for filename in test_list:\n",
    "    img,lbl = get_sample(filename,image_folder,label_folder)\n",
    "    lbl = np.argmax(lbl,axis=-1)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    img = np.expand_dims(img,axis=-1)\n",
    "    img_pred = network.predict(img)\n",
    "    pred = np.argmax(img_pred[0,:,:,:],axis=-1)\n",
    "    matplotlib.image.imsave(prediction_folder+filename,pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_folder = '/home/dspuser/MA499/Predictions/' #Folder for predictions\n",
    "test_list = valid_list\n",
    "for filename in test_list:\n",
    "    img,lbl = get_sample(filename,image_folder,label_folder)\n",
    "    lbl = np.argmax(lbl,axis=-1)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    img = np.expand_dims(img,axis=-1)\n",
    "    img_pred = network.predict(img)\n",
    "    pred = np.argmax(img_pred[0,:,:,:],axis=-1)\n",
    "    matplotlib.image.imsave(prediction_folder+filename,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[4.08953913e-02, 9.59104598e-01],\n",
       "         [2.86899805e-01, 7.13100255e-01],\n",
       "         [2.55960273e-04, 9.99743998e-01],\n",
       "         ...,\n",
       "         [5.55715133e-07, 9.99999404e-01],\n",
       "         [2.59438650e-07, 9.99999762e-01],\n",
       "         [1.01332866e-01, 8.98667097e-01]],\n",
       "\n",
       "        [[1.43952379e-02, 9.85604703e-01],\n",
       "         [1.61494652e-04, 9.99838471e-01],\n",
       "         [3.84293380e-04, 9.99615669e-01],\n",
       "         ...,\n",
       "         [4.71111089e-02, 9.52888906e-01],\n",
       "         [1.61086628e-08, 1.00000000e+00],\n",
       "         [4.65085894e-01, 5.34914076e-01]],\n",
       "\n",
       "        [[9.20047518e-04, 9.99079943e-01],\n",
       "         [9.09818470e-01, 9.01815668e-02],\n",
       "         [1.36495659e-08, 1.00000000e+00],\n",
       "         ...,\n",
       "         [2.37011317e-08, 1.00000000e+00],\n",
       "         [8.35604386e-09, 1.00000000e+00],\n",
       "         [4.16931385e-07, 9.99999642e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[8.59623123e-03, 9.91403759e-01],\n",
       "         [7.50332233e-03, 9.92496729e-01],\n",
       "         [4.41316705e-11, 1.00000000e+00],\n",
       "         ...,\n",
       "         [8.85718942e-01, 1.14281073e-01],\n",
       "         [3.61273110e-01, 6.38726890e-01],\n",
       "         [2.51686007e-01, 7.48313963e-01]],\n",
       "\n",
       "        [[1.11171914e-11, 1.00000000e+00],\n",
       "         [4.63819169e-02, 9.53618050e-01],\n",
       "         [2.55912650e-24, 1.00000000e+00],\n",
       "         ...,\n",
       "         [2.14681113e-05, 9.99978542e-01],\n",
       "         [4.91014635e-03, 9.95089769e-01],\n",
       "         [8.90728272e-03, 9.91092741e-01]],\n",
       "\n",
       "        [[3.02690609e-07, 9.99999642e-01],\n",
       "         [1.56294334e-16, 1.00000000e+00],\n",
       "         [8.70737094e-10, 1.00000000e+00],\n",
       "         ...,\n",
       "         [1.81320909e-04, 9.99818742e-01],\n",
       "         [1.22006582e-02, 9.87799287e-01],\n",
       "         [9.09577124e-03, 9.90904272e-01]]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from random import shuffle\n",
    "import scipy.misc\n",
    "import scipy\n",
    "import time\n",
    "import skimage.io\n",
    "from skimage.io import imread\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras import optimizers, metrics, regularizers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, SeparableConv2D, core\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, Cropping2D, concatenate, Input\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.activations import softmax\n",
    "import matplotlib\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_weight_one = 1\n",
    "class_weight_two = 1\n",
    "batch_size = 2\n",
    "epochs_2_train = 10\n",
    "validPercent = 0.1\n",
    "image_folder = '/data/Ro_ImageData/Low SN ratio ceramic images/' #Source of images\n",
    "label_folder = '/data/Ro_ImageData/32xOTSU/' #Otsu images\n",
    "highSN_folder = '/data/Ro_ImageData/High SN ratio ceramic images/'\n",
    "lowSN_folder = '/data/Ro_ImageData/Low SN ratio ceramic images/'\n",
    "prediction_folder = '/home/dspuser/MA499/Predictions/' #Folder for predictions\n",
    "\n",
    "'''\n",
    "sampleListAll = os.listdir(image_folder)\n",
    "\n",
    "for file in sampleListAll:\n",
    "    if os.path.splitext(file)[1] == '.tiff':\n",
    "        sampleList.append(file)\n",
    "'''\n",
    "\n",
    "def makeSampleList(highSN_folder,lowSN_folder,sampleSize,prop):\n",
    "    highSN = os.listdir(highSN_folder)\n",
    "    highSN = [os.path.join(highSN_folder,file) for file in highSN]\n",
    "    lowSN = os.listdir(lowSN_folder)\n",
    "    lowSN = [os.path.join(lowSN_folder,file) for file in lowSN]\n",
    "    highSample = list(np.random.choice(highSN,2000-round(2000*0.025)))\n",
    "    lowSample = list(np.random.choice(lowSN,round(2000*0.025)))\n",
    "    sampleList = highSample + lowSample\n",
    "    for file in sampleList:\n",
    "        if os.path.splitext(file)[1] == '.tiff':\n",
    "            sampleList.append(file)\n",
    "    return sampleList\n",
    "\n",
    "sampleList = makeSampleList(highSN_folder,lowSN_folder,2000,0.025)\n",
    "sampleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "highSN = os.listdir(highSN_folder)\n",
    "highSN = [os.path.join(highSN_folder,file) for file in highSN]\n",
    "lowSN = os.listdir(lowSN_folder)\n",
    "lowSN = [os.path.join(lowSN_folder,file) for file in lowSN]\n",
    "highSample = list(np.random.choice(highSN,2000-round(2000*0.025)))\n",
    "lowSample = list(np.random.choice(lowSN,round(2000*0.025)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
